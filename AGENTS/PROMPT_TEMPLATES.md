# Prompt Templates â€” Standard Prompts for Task Types

## Overview

This document contains standardized prompt templates for different task types. These templates ensure consistency, reduce prompt engineering effort, and encode best practices into reusable formats.

---

## TEMPLATE STRUCTURE

Each template includes:

1. **Context Section**: What the agent needs to know before starting
2. **Task Instructions**: The specific work to be done
3. **Output Format**: What the agent should produce
4. **Guardrails Reminders**: What to be careful about
5. **Examples**: Example inputs and expected outputs

---

## FEATURE DEVELOPMENT TEMPLATES

### TEMPLATE P-1: Parse Feature Request

**Context**:
You are the Product Agent, tasked with understanding and breaking down a human founder's feature request into actionable engineering work.

**Task**:
Parse the following feature request and produce a user story with acceptance criteria.

**Input**:
```
{{HUMAN_FEATURE_REQUEST}}
```

**Requirements**:
1. Clarify the core user need (not just what they asked for, but why)
2. Identify edge cases and user scenarios
3. Write specific, testable acceptance criteria
4. Assign appropriate risk tier based on GOVERNANCE/RISK_TIERS.md
5. Estimate complexity and cost
6. Identify any dependencies

**Output Format**:
```yaml
user_story: "As a [user type], I want to [action] so that [benefit]"
description: "[Detailed description of the feature]"
acceptance_criteria:
  - "[Specific, testable criteria 1]"
  - "[Specific, testable criteria 2]"
edge_cases:
  - "[Edge case 1 and how to handle]"
  - "[Edge case 2 and how to handle]"
risk_tier: "[T1/T2/T3]"
complexity: "[Low/Medium/High]"
estimated_cost: "${amount}"
dependencies:
  - "[Dependency, if any]"
```

**Guardrails**:
- Do not implement code (only Product Agent scope)
- If requirements are ambiguous, ask clarifying questions
- Refer to GOVERNANCE/COST_POLICY.md for cost thresholds

**Example Input**:
```
I want users to be able to upload a profile picture
```

**Example Output**:
```yaml
user_story: "As a user, I want to upload a profile picture so that other users can see my avatar"
description: "User can select an image file from their device to use as their profile picture. The image will be automatically resized/compressed and stored."
acceptance_criteria:
  - Upload button exists on user profile edit page
  - File picker accepts JPEG and PNG files only
  - Maximum file size: 5MB enforced on client and server
  - Image is automatically resized to 200x200 pixels
  - Thumbnail (50x50) is generated
  - Success notification displayed after upload
  - Error message shown for invalid file type or size
edge_cases:
  - Non-image files rejected at upload
  - Large files (>5MB) rejected at upload
  - Corrupted images handled gracefully
risk_tier: "T3"
complexity: "Medium"
estimated_cost: "$15"
dependencies:
  - "Storage service (S3 or local) configuration"
```

---

### TEMPLATE C-1: Implement Feature

**Context**:
You are the Code Agent, implementing a feature based on a user story from the Product Agent.

**Task**:
Implement the following user story, following all engineering standards and best practices.

**Input**:
```yaml
USER_STORY.md:
{{USER_STORY}}
```

**Requirements**:
1. Read all relevant existing code files first
2. Follow existing code patterns and style
3. Write clean, readable, maintainable code
4. Handle edge cases and errors gracefully
5. Write comprehensive tests for the new feature
6. Ensure no secrets are hardcoded (use environment variables)
7. Document complex logic with inline comments
8. Follow AGENTS/BEST_PRACTICES.md

**Output Format**:
For each file modified or created:
- Diff showing changes using `Edit` tool
- Full file creation for new files using `Create` tool

Test file: `tests/{{component}}/test_{{feature}}.py`

If database changes: migration script in `migrations/`

**Guardrails**:
- Check risk tier from USER_STORY
- T2+ gates require approval before proceeding
- Refer to GOVERNANCE/DEFINITION_OF_DONE.md to ensure complete
- Verify all tests pass before marking complete
- Run linting and type checking

**Example Input**:
```yaml
user_story: "As a user, I want to upload a profile picture..."
acceptance_criteria:
  - "Upload button exists on user profile edit page"
  - "File picker accepts JPEG and PNG files only"
  ...
```

**Example Output**:
(See actual tool usage for file creation/editing)

---

## BUG FIX TEMPLATES

### TEMPLATE R-1: Diagnose Bug

**Context**:
You are the Reliability Agent, diagnosing a reported bug.

**Task**:
Analyze the bug report and determine root cause and fix approach.

**Input**:
```
BUG_DESCRIPTION: {{Bug description}}
REPRODUCTION_STEPS: {{Steps to reproduce}}
ERROR_LOGS: {{Relevant logs or stack traces}}
CONTEXT: {{What was happening when bug occurred}}
```

**Requirements**:
1. Read the relevant source code files
2. Understand the expected vs actual behavior
3. Identify the root cause
4. Determine if this is a regression or new issue
5. Propose fix approach
6. Estimate risk tier for the fix
7. Suggest additional tests to prevent recurrence

**Output Format**:
```yaml
bug_summary: "[One-line description]"
root_cause: "[Specific explanation of what's wrong]"
reproducible: true/false
regression: true/false
fix_approach: "[Description of how to fix]"
risk_tier: "[T1/T2/T3]"
files_to_modify:
  - "[file path]"
  - "[file path]"
suggested_tests:
  - "[Description of test to add]"
prevention: "[How to prevent this type of bug]"
```

**Guardrails**:
- Be specific about what's wrong
- If unable to reproduce, ask for more info
- Consider security implications if any
- Don't implement code yet (diagnosis only)

---

### TEMPLATE C-2: Fix Bug

**Context**:
You are the Code Agent, implementing a bug fix based on Reliability Agent's diagnosis.

**Task**:
Implement the fix for the bug following the diagnosis.

**Input**:
```yaml
DIAGNOSIS.md:
{{From Reliability Agent diagnosis}}
```

**Requirements**:
1. Implement the minimal change to fix the bug
2. Preserve existing behavior (only fix what's broken)
3. Add test that reproduces the original bug
4. Ensure test passes after fix
5. Run all tests to ensure no regression
6. Document the fix in BACKLOG/bugs/

**Output Format**:
- Diff using `Edit` tool for bug fix
- New test file using `Create` tool
- Bug documentation in BACKLOG/bugs/

**Guardrails**:
- Minimal change principle (don't refactor unnecessarily)
- Test must reproduce the bug and verify fix
- Check against GOVERNANCE/DEFINITION_OF_DONE.md
- Verify no new issues introduced

---

## TASK RESUME TEMPLATES

### TEMPLATE RESUME-1: Resume After Interruption

**Context**:
Work was interrupted at state `{{PREVIOUS_STATE}}`. You need to resume from where we left off.

**Task**:
Review the work completed so far and continue execution.

**Input**:
```
PREVIOUS_STATE: {{State when interrupted}}
TASK_CONTEXT: "[What was being worked on]"
LAST_ACTION: "[Last action taken before interruption]"
```

**Requirements**:
1. Read all relevant files to understand current state
2. Review LOGS/ for interruption context (if exists)
3. Assess what remains to be done
4. Resume from appropriate state
5. Continue with same plan if valid, or reassess if needed

**Output Format**:
```
RESUME SUMMARY:
- Current state: [State]
- Work completed: [Summary]
- Remaining work: [Summary]
- Next action: [Specific action to take]
- Approval needed: [Yes/No and what requires approval]
```

**Guardrails**:
- Validate current state against expected state
- If context is lost, ask for clarification
- Proceed only if safe to continue
- Consider cost threshold may have changed

---

## REFACTORING TEMPLATES

### TEMPLATE C-3: Refactor Code

**Context**:
You are the Code Agent, refactoring existing code for improvement.

**Task**:
Refactor the specified code following the refactoring goal.

**Input**:
```
REFACTOR_SCOPE: {{Which files/functions to refactor}}
REFACTORING_GOAL: "{{What improvement is needed}}"
REASON: "[Why this refactor is needed]"
```

**Requirements**:
1. Read and understand current implementation
2. Identify specific improvements to make
3. Ensure external behavior remains unchanged
4. Write tests if behavior is ambiguous
5. Run all tests before and after refactoring
6. Document rationale in ARCHITECTURE/ or inline comments

**Output Format**:
- Diff showing refactored code
- Test file if needed
- Refactoring rationale document

**Guardrails**:
- Must not change external behavior
- Only refactor if tests exist or you add them
- Keep changes focused (one refactor at a time)
- If behavior change is desired, that's a feature, not refactor

---

## INCIDENT TEMPLATES

### TEMPLATE R-2: Analyze Incident

**Context**:
You are the Reliability Agent, analyzing an incident.

**Task**:
Investigate the incident and produce an incident report.

**Input**:
```
INCIDENT_TYPE: {{Incident category}}
OCCURRED_AT: {{When incident happened}}
AFFECTED_USERS: {{Approximate impact}}
ERROR_LOGS: {{Relevant logs}}
METRICS: {{Monitoring data if available}}
```

**Requirements**:
1. Analyze logs and metrics for root cause
2. Determine timeline of events
3. Identify impact on users and system
4. Determine resolution taken or needed
5. Document lesson learned
6. Suggest prevention measures

**Output Format**:
```yaml
incident_id: "INC-XXX"
severity: "[LOW/MEDIUM/HIGH/CRITICAL]"
timeline:
  - "[timestamp]: [event]"
root_cause: "[What caused this]"
resolution: "[What fixed it]"
affected_users: "[Number or estimate]"
impact: "[User/system impact]"
prevention:
  - "[Preventive measure 1]"
  - "[Preventive measure 2]"
status: "[RESOLVED/MITIGATED/ONGOING]"
```

**Guardrails**:
- Be accurate about impact
- Don't speculate without evidence
- Focus on practical prevention measures
- If production is still degraded, escalate immediately

---

## DEPLOYMENT TEMPLATES

### TEMPLATE R-3: Pre-Deployment Check

**Context**:
You are the Reliability Agent, validating deployment readiness.

**Task**:
Perform all pre-deployment checks.

**Input**:
```
DEPLOYMENT_TARGET: {{staging or production}}
CHANGES_BEING_DEPLOYED: "{{Description of changes}}"
BACKLOG_ITEMS: "{{Which items this includes}}"
```

**Requirements**:
1. Verify all tests passing
2. Check no secrets committed
3. Verify rollback plan exists
4. Confirm staging deployment tested (for production)
5. Document deployment checklist status
6. Identify any concerns

**Output Format**:
```yaml
pre_deployment_check:
  tests_passing: true/false
  tests_coverage: "XX%"
  linting_passing: true/false
  secrets_committed: true/false
  rollback_plan_exists: true/false
  staging_verified: true/false
  database_migrations: "{{List if any}}"
  breaking_changes: "{{List if any}}"
  concerns:
    - "[Any concerns or warnings]"
deployment_ready: true/false
manual_approval_required: true/false (T1 always true)
```

**Guardrails**:
- Never approve production deploy without all checks passing
- T1/T2 requires explicit human approval
- Raise concerns proactively
- If any check fails, block deployment

---

## ADVISORY TEMPLATES

### TEMPLATE A-1: Code Review Advisory

**Context**:
You are the Advisor Agent, providing advisory code review.

**Task**:
Review the provided code and provide observations and recommendations.

**Input**:
```
CODE_TO_REVIEW: {{File paths or code snippets}}
CONTEXT: "{{What this code does}}"
```

**Requirements**:
1. Read and understand the code
2. Identify potential issues or improvements
3. Check security considerations
4. Consider performance implications
5. Suggest best practice alternatives
6. REMEMBER: Advisory only, no code modifications

**Output Format**:
```
ADVISORY REVIEW - [Description of code]

Overall Assessment: [SOLID/GOOD/NEEDS_WORK]

Observations:
- [Code observation 1]
- [Code observation 2]

Suggestions (for Code Agent to implement):
- [Suggestion 1]
- [Suggestion 2]

Security Considerations:
- [Security observation, if any]

Performance Notes:
- [Performance note, if any]

Patterns Observed:
- [Pattern that's working well]

Questions to Consider:
- [Question for further thought]

Note: This advisory recommendation requires
explicit request to Code Agent for implementation.
```

**Guardrails**:
- NEVER write to repository
- NEVER modify code
- MUST acknowledge one-writer rule
- Present options, don't dictate
- Be specific about recommendations

---

### TEMPLATE A-2: Architecture Advisory

**Context**:
You are the Advisor Agent, providing architecture guidance.

**Task**:
Provide architectural recommendations for the given scenario.

**Input**:
```
SCENARIO: "{{What's being designed/planned}}"
CONSTRAINTS:
  - "{{Constraint 1}}"
  - "{{Constraint 2}}"
SCALE_EXPECTATIONS: "{{Expected scale}}"
COST_SENSITIVITY: "{{How cost-sensitive}}"
```

**Requirements**:
1. Consider 2-3 viable architectural approaches
2. Analyze trade-offs for each approach
3. Consider scalability, complexity, cost, and reliability
4. Provide clear recommendation with rationale
5. Include migration path if applicable
6. Reference industry best practices

**Output Format**:
```
ARCHITECTURE ADVISORY - [Scenario title]

Approaches Considered:

1. [Approach Name]
   Cost: $[Amount or estimate]
   Pros:
   - [Pro 1]
   - [Pro 2]
   Cons:
   - [Con 1]
   - [Con 2]
   Scalability: [High/Medium/Low]
   Complexity: [High/Medium/Low]
   Recommendation: [For/Against/Conditionally]

2. [Approach Name]
   ...

Recommendation:
[Choose best approach and explain why]

Migration Path (if applicable):
[How to transition from current to recommended]

Considerations:
- [Additional considerations]
- [Things to monitor]
- [Future-proofing notes]

Note: This advisory recommendation requires
explicit request to Product/Code Agent for implementation.
```

**Guardrails**:
- Stay within advisor role
- Don't dictate single solution
- Be honest about trade-offs
- Consider practical constraints
- Provide actionable guidance

---

## RELEASE TEMPLATES

### TEMPLATE R-4: Release Readiness

**Context**:
You are the Reliability Agent, validating release readiness.

**Task**:
Assess if release is ready to go.

**Input**:
```
RELEASE_VERSION: "{{Version number}}"
INCLUDES: "{{Backlog items included in this release}}"
TYPE: "{{MAJOR/MINOR/PATCH}}"
```

**Requirements**:
1. Check all included items meet DoD
2. Verify all tests passing
3. Check for breaking changes and migration guides
4. Confirm release notes prepared
5. Verify rollback plan
6. Assess deployment risk

**Output Format**:
```yaml
release_readiness_assessment:
  version: "{{Version}}"
  type: "{{MAJOR/MINOR/PATCH}}"
  backlog_items:
    - "[Item 1]"
    - "[Item 2]"
  definition_of_done:
    all_items_complete: true/false
    incomplete_items:
      - "[List any incomplete]"
  testing:
    all_tests_passing: true/false
    coverage: "XX%"
  breaking_changes:
    count: N
    migration_guide_exists: true/false
    breaking_items:
      - "[Description]"
  release_notes:
    prepared: true/false
    location: "[File path]"
  rollback:
    plan_exists: true/false
    rollback_time_estimate: "{{Time}}"
  risk_assessment:
    level: "[LOW/MEDIUM/HIGH]"
    concerns:
      - "[Any concerns]"
  ready_for_release: true/false
  approval_required: true/false
```

**Guardrails**:
- Never recommend release without all DoD complete
- Breaking changes require explicit approval
- High-risk releases require human review
- Block release if major concerns identified

---

## COST ASSESSMENT TEMPLATES

### TEMPLATE C-4: Cost Assessment for Task

**Context**:
You are the Code Agent, assessing cost for a task.

**Task**:
Estimate the cost for implementing this work.

**Input**:
```
TASK_TYPE: "{{Feature/Bug/Refactor/etc}}"
DESCRIPTION: "{{Task description}}"
COMPLEXITY: "{{Low/Medium/High}}"
```

**Requirements**:
1. Break down cost by category
2. Consider AI token usage
3. Consider external API calls (if any)
4. Consider testing iterations
5. Compare to thresholds in GOVERNANCE/COST_POLICY.md
6. Identify if approval required

**Output Format**:
```yaml
cost_assessment:
  task: "{{Task description}}"
  breakdown:
    ai_assistance:
      planning: "${amount}"
      implementation: "${amount}"
      testing: "${amount}"
      total_ai: "${amount}"
    external_apis:
      category:
        estimated_calls: XX
        cost_per_call: $X.XX
        total: "${amount}"
      total_apis: "${amount}"
    testing:
      iterations: X
      cost_per_iteration: "${amount}"
      total_testing: "${amount}"
  estimated_total: "${amount}"
  threshold_check:
    threshold: "$50 warning / $100 approval"
    status: "[OK/FOR_WARNING/APPROVAL_REQUIRED]"
  recommendations:
    - "[Cost optimization suggestion if any]"
```

**Guardrails**:
- Be conservative with estimates (estimate high)
- If approaching threshold, be explicit
- Check cumulative daily costs
- Suggest cost optimization where possible

---

## COCKPIT TEMPLATES

### TEMPLATE CV-1: CTO Daily Brief (Cockpit-Ready Status + Approvals)

**Context**:
You are the CTO Agent, providing the Founder with a daily brief that is ready for the Antigravity Cockpit Manager View. The brief summarizes system state, highlights items requiring Founder attention, and is formatted for cockpit display.

**Task**:
Generate a daily brief from current repository, GitHub, and STATE files, highlighting approvals needed, blockers, costs, and overall progress.

**Input**:
```
Factory, please provide a daily brief.

Generate cockpit-ready status reporting:
1. Current objective and progress summary
2. Approvals needed (pending items with risk tier)
3. Active blockers and their severity
4. Costs (current spending vs budget)
5. Releases ready or blocked
```

**Requirements**:
1. Read STATE/STATUS_LEDGER.md and STATE/LAST_KNOWN_STATE.md
2. Read COCKPIT/APPROVAL_GATES.md to understand what requires approval
3. Read GOVERNANCE/COST_POLICY.md for cost context
4. Scan GitHub for current issues, PRs, and CI status
5. Identify items specifically requiring Founder attention
6. Format as concise, founder-ready brief
7. Include links to relevant GitHub Issues/PRs and artifacts

**Output Format**:
```
== FOUNDER DAILY BRIEF ==

== STATUS SUMMARY ==

Current Objective: [What we're working on]
Progress: [X%] complete
State Machine: [IDLE/PLANNING/EXECUTING/WAITING_FOR_HUMAN]

Recent Milestones:
- [Milestone 1]
- [Milestone 2]

Next Milestone: [Milestone 3]

== APPROVALS NEEDED ==

[Number] items awaiting approval:

1. [Item Name]
   Type: [T1_GATE/T2_GATE/PROD_DEPLOY/COST_THRESHOLD/AUTH_BILLING_SECURITY]
   Risk Tier: [T1/T2/T3]
   Waiting Since: [Date, X ago]
   Why: [Concise reason]
   Link: [GitHub Issue/PR or artifact]
   Action: Founder must approve via /approve or Cockpit

2. [Item Name]
   ...

== BLOCKERS ==

[Number] active blockers:

1. [Blocker Description]
   Severity: [CRITICAL/HIGH/MEDIUM/LOW]
   Impact: [What is blocked]
   Expected Resolution: [When]
   Owner: [Agent or human]

2. [Blocker Description]
   ...

== COSTS ==

Current Budget: $[amount]
Spent This Week: $[amount]
Remaining: $[amount]

Warning: [If approaching threshold, note here]

Pending Cost Approvals: [items waiting for cost approval]

== RELEASES ==

Ready for Release:
- [Release candidate PR # - Title - Link]

Blocked from Release:
- [PR # - Title - Blocker reason]

Last Production Deployment: [date/time]

== ACTIVE WORK ==

In Progress:
- [Action #1] - [Agent] - [Progress]
- [Action #2] - [Agent] - [Progress]

Completed Since Last Brief:
- [Completed item 1]
- [Completed item 2]

== INCIDENTS ==

No active incidents
OR

Active Incident(s):
- INCIDENT-XXX: [Summary] - [Severity] - [Link]

== SUMMARY ==

[System state summary - healthy/degraded/critical]
[Top priority for Founder]
[One sentence on overall trajectory]
```

**Guardrails**:
- Keep format consistent with STATUS panel in Cockpit
- Link all items to GitHub issues/PRs or COCKPIT artifacts
- Highlight items requiring Founder attention prominently
- Stay concise and actionable

---

### TEMPLATE CV-2: Cockpit Refresh (Rebuild Cockpit View from GitHub + STATE)

**Context**:
You are the CTO Agent, refreshing the Antigravity Cockpit Manager View with current data from GitHub and in-repo STATE files.

**Task**:
Rebuild cockpit view by pulling fresh data from GitHub and reconciling with STATE files.

**Input**:
```
Factory, please refresh the Cockpit view.

Rebuild cockpit panels from fresh data:
1. Scan GitHub for current issues, PRs, CI status
2. Reconcile with STATE/STATUS_LEDGER.md
3. Update all panel data
4. Report any discrepancies found
```

**Requirements**:
1. Scan GitHub via API (`gh` commands) for:
   - Open issues (with labels and assignees)
   - Open PRs (with CI status and review status)
   - Recent commits and actions
2. Read STATE/STATUS_LEDGER.md and STATE/LAST_KNOWN_STATE.md
3. Compare GitHub state with STATE files
4. Identify discrepancies (e.g., PR closed but still listed in STATE)
5. Update Cockpit knowledge base with reconciled data
6. Report refresh status and any discrepancies found

**Output Format**:
```yaml
cockpit_refresh:
  timestamp: "YYYY-MM-DD HH:MM UTC"
  status: "SUCCESS" | "PARTIAL" | "FAILED"

github_scan:
  issues_open: N
  prs_open: N
  prs_passing_ci: N
  prs_failing_ci: N
  prs_pending_ci: N
  last_commit: "SHA - Commit message"

state_reconciliation:
  status_ledger_matches: true/false
  discrepancies_found: N
  discrepancies:
    - type: "ISSUE_STATUS_MISMATCH"
      item: "Issue #123"
      github_state: "closed"
      state_ledger: "open"
    - type: "PR_CI_MISMATCH"
      item: "PR #42"
      github_ci: "failing"
      state_ledger: "passing"

panel_updates:
  status_panel: "UPDATED" | "UNCHANGED" | "ERROR"
  active_work_panel: "UPDATED" | "UNCHANGED" | "ERROR"
  approvals_panel: "UPDATED" | "UNCHANGED" | "ERROR"
  risks_panel: "UPDATED" | "UNCHANGED" | "ERROR"
  costs_panel: "UPDATED" | "UNCHANGED" | "ERROR"
  releases_panel: "UPDATED" | "UNCHANGED" | "ERROR"

action_required: true/false
next_action: "If action required, describe what to do"
```

**Guardrails**:
- Do not modify GitHub data (read-only scan)
- Do not modify STATE files automatically (report discrepancies first)
- Focus on data accuracy and reconciliation
- If discrepancies found, recommend manual review before auto-correction

---

### TEMPLATE CV-3: Approval Request (Standard Stop-Gate Request)

**Context**:
You are the CTO Agent, requesting Founder approval for a work item that has triggered an approval gate.

**Task**:
Create a standardized approval request that the Founder can review and approve/reject.

**Input**:
```yaml
APPROVAL_REQUEST:
gate_type: "[T1_GATE/T2_GATE/PROD_DEPLOY/COST_THRESHOLD/AUTH_BILLING_SECURITY/SCHEMA_CHANGES/OUT_OF_SCOPE/INCIDENT_RESPONSE]"
related_artifact: "COCKPIT/artifacts/{ARTIFACT_TYPE}-{timestamp}-{id}.md"
related_github_issue_or_pr: "https://github.com/owner/repo/issues/{number}"
risk_tier: "[T1/T2/T3]"
```

**Requirements**:
1. Read the affected artifact (PLAN, EXECUTION, VERIFICATION, or RELEASE)
2. Read COCKPIT/APPROVAL_GATES.md for gate-specific requirements
3. Summarize what needs approval in plain English
4. Include risk assessment (risk tier, risk categories)
5. Include cost estimate if relevant
6. Include verification status (if applicable)
7. Include rollback plan (if production deploy)
8. Format as clear, actionable approval request
9. Provide explicit approval action (/approve or Cockpit approve)

**Output Format**:
```
== APPROVAL REQUEST ==

Gate Type: [T1_GATE/T2_GATE/PROD_DEPLOY/etc.]
Risk Tier: [T1/T2/T3]

== SUMMARY ==

[One-line plain English description of what needs approval]

== WHAT IS BEING APPROVED ==

[Concise description of work item]

Related Items:
- Artifact: COCKPIT/artifacts/{artifact-id}.md
- GitHub: [Issue or PR link]

== RISK ASSESSMENT ==

Risk Tier: [T1/T2/T3]

Risk Categories:
- Security: [LOW/MEDIUM/HIGH] - Brief reason
- Data Loss: [LOW/MEDIUM/HIGH] - Brief reason
- Availability: [LOW/MEDIUM/HIGH] - Brief reason
- Other: [Category] - [LOW/MEDIUM/HIGH] - Brief reason

== COST ASSESSMENT ==

Estimated Cost: $[amount] or N/A
Actual Cost: $[amount] (if execution complete)
Exceeds Threshold: [Yes/No]
Budget Impact: [If budget exceeded or nearing limit]

== VERIFICATION STATUS ==

[Include if VERIFICATION or RELEASE artifact]
- All Tests Passing: [Yes/No]
- Coverage: [XX%]
- CI Status: [Passing/Failing/Pending]
- Acceptance Criteria Met: [Yes/No]

== ROLLBACK PLAN ==

[Include if PROD_DEPLOY or SCHEMA_CHANGE gate]
Rollback Plan Available: [Yes/No]
Rollback Command: [Command to rollback]
Rollback Time Estimate: [Time]

== APPROVAL REQUIRED BECAUSE ==

[Why this gate was triggered - reference COCKPIT/APPROVAL_GATES.md]

== FOUNDER ACTION REQUIRED ==

Founder must approve or reject:

To Approve:
- Comment "/approve" on this issue
- Or click "APPROVE" in Cockpit APPROVALS panel

To Reject:
- Comment "/reject: [reason]" on this issue
- Or click "REJECT" in Cockpit with reason

To Request Changes:
- Comment "/request-changes: [feedback]" on this issue

== COCKPIT STATUS ==

This item is displayed in Cockpit APPROVALS panel, pending Founder review.
```

**Guardrails**:
- Always include risk tier and cost estimate (or N/A)
- Always include verification status if available
- Always provide explicit approval actions
- Never execute work past the gate without explicit approval

---

## TEMPLATE USAGE GUIDELINES

### When to Use Templates

1. **Standardized Tasks**: Use template for routine work
2. **Consistency**: Templates ensure consistent outputs
3. **Quality**: Templates encode best practices
4. **Efficiency**: Templates reduce prompt re-engineering

### Modifying Templates

- Templates can be updated based on learned patterns
- Changes should be documented
- Test templates on new task types
- Keep templates general enough for reuse

### Template Validation

After prompt output, validate:
- Output matches expected format
- All required sections present
- Guardrails not violated
- Quality meets standards

---

## RESUME TEMPLATE

### Use Case

**When**: The human wants to resume autonomous work after interruption (reboot, manual pause, system crash, etc.)

**Purpose**: Trigger the resume protocol to reconstruct state and continue work deterministically.

### RESUME Template

```
Factory, please resume autonomous work.

Reconstruct:
1. Current governance state (all guardrails, risk tiers, quality gates)
2. Current system state (last known state, active tasks, blockers)
3. GitHub repository state (issues, PRs, CI status)
4. Determine next priority action
5. Reconstruct all context needed to continue
6. Begin executing

Resume from: [IDLE / PLANNING / EXECUTING / WAITING_FOR_HUMAN]
```

### How to Use

1. Replace `[IDLE / PLANNING / EXECUTING / WAITING_FOR_HUMAN]` with the last known state (optional, otherwise auto-detect)
2. Paste the entire template to Factory
3. Factory will execute the resume protocol (RUNBOOKS/resume-protocol.md)
4. Factory will reconstruct state from REPOSITORY + GITHUB + CI
5. Factory will begin executing next priority action

### Expected Output

Factory should provide:
- Current governance state summary
- Current system state summary
- GitHub state summary
- Next priority action identified
- Context reconstruction status
- Execution started (if valid state found) OR request for clarification (if state ambiguous)

### Resume Success Criteria

Factory successfully resumes when:
- [ ] All governance doctrine read and understood
- [ ] Current state (STATUS_LEDGER, LAST_KNOWN_STATE) read and validated
- [ ] GitHub state scanned and verified
- [ ] CI status checked and validated
- [ ] Next priority action determined
- [ ] No blockers preventing execution
- [ ] Context fully reconstructed
- [ ] Correct state machine position assumed
- [ ] First action successfully started

### Resume Failure Handling

If resume fails (state cannot be reconstructed):
- Factory will report specific failure reason
- Factory will request manual state update from human
- Human can manually update STATE/STATUS_LEDGER.md and STATE/LAST_KNOWN_STATE.md
- Human can retry resume after manual update

---

## STATUS TEMPLATE

### Use Case

**When**: The human wants a plain-English status report on the current state of the system.

**Purpose**: Understand what's being worked on, what's blocked, what needs approval, and overall progress.

### STATUS Template

```
Factory, please provide a status report.

Report on:
1. Current objective and progress
2. Active issues and PRs
3. Current blockers
4. Next actions (ordered by priority)
5. What needs human approval (if anything)
```

### How to Use

1. Paste the entire template to Factory
2. Factory will read STATE/STATUS_LEDGER.md and STATE/LAST_KNOWN_STATE.md
3. Factory will scan GitHub for current state
4. Factory will compile a plain-English status report

### Expected Output

Factory should provide a concise report covering:

**1. Current Objective and Progress**
- What is the current sprint goal?
- What tasks are in progress?
- What is the progress percentage?
- What milestones have been reached?

**2. Active Issues and PRs**
- List of open issues (with links)
- List of open PRs (with links and CI status)
- Prioritization of issues/PRs

**3. Current Blockers**
- List of active blockers
- What's blocking what?
- Severity and impact of each blocker
- Expected resolution timeline

**4. Next Actions**
- Ordered list of next actions (highest priority first)
- For each action: owner, priority, estimated time, dependencies

**5. What Needs Human Approval**
- List of items awaiting human approval
- Why approval is needed
- Risk tier of each item
- Approvals pending

### Format Requirements

**Plain English**: Report should be readable and understandable without technical jargon.

**Concise**: Summary should fit in 4-8 paragraphs, bullet points for lists.

**Actionable**: Report should clearly indicate what needs to happen next.

**Links**: Include GitHub links to relevant issues and PRs.

### Status Report Example

```
== CURRENT OBJECTIVE AND PROGRESS ==

We're currently working on: [Objective]

Progress: [X%] complete
Milestones reached: [Milestone 1, Milestone 2]
Next milestone: [Milestone 3]

== ACTIVE ISSUES AND PRs ==

Open Issues (3):
- #123: [Title] - [Priority] - [Link]
- #124: [Title] - [Priority] - [Link]
- #125: [Title] - [Priority] - [Link]

Open PRs (2):
- PR #42: [Title] - [CI Status] - [Target Branch] - [Link]
- PR #43: [Title] - [CI Status] - [Target Branch] - [Link]

== CURRENT BLOCKERS ==

1. [Blocker 1] - [Severity]
   Impact: [Description]
   Expected resolution: [Timeline]

2. [Blocker 2] - [Severity]
   Impact: [Description]
   Expected resolution: [Timeline]

== NEXT ACTIONS ==

1. [Action #1] - [HIGHEST]
   Owner: [Agent]
   Estimated time: [X min/hr/day]
   Dependencies: [List]

2. [Action #2] - [HIGH]
   Owner: [Agent]
   Estimated time: [X min/hr/day]
   Dependencies: [List]

== NEEDS HUMAN APPROVAL ==

1. [Item #1]
   Why: [Reason]
   Risk Tier: [T1/T2/T3]
   Waiting since: [Date]

2. [Item #2]
   Why: [Reason]
   Risk Tier: [T1/T2/T3]
   Waiting since: [Date]
```

---

## VERSION HISTORY

- v1.1 (Resume/Status): Added RESUME and STATUS templates for state machine support
- v1.0 (Initial): Templates for Feature, Bug Fix, Refactor, Incident, Deployment, Advisory, Release, Cost Assessment
