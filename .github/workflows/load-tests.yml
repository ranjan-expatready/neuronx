name: Load Tests

on:
  schedule:
    # Run load tests weekly on Sundays at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      leads_per_minute:
        description: 'Leads per minute for load test'
        required: false
        default: '15'
        type: number
      duration_minutes:
        description: 'Test duration in minutes'
        required: false
        default: '5'
        type: number

jobs:
  load-test:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: neuronx_load_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Setup test environment
        run: |
          cp .env.example .env.loadtest
          echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/neuronx_load_test" >> .env.loadtest
          echo "REDIS_URL=redis://localhost:6379" >> .env.loadtest
          echo "CIPHER_ENABLED=true" >> .env.loadtest
          echo "NODE_ENV=production" >> .env.loadtest

      - name: Build application
        run: npm run build

      - name: Start application
        run: npm run start:prod &
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/neuronx_load_test
          REDIS_URL: redis://localhost:6379
        id: start-app

      - name: Wait for application to be ready
        run: |
          timeout 120 bash -c 'until curl -f http://localhost:3000/health; do sleep 5; done' || (echo "Application failed to start" && exit 1)

      - name: Health check validation
        run: |
          HEALTH_RESPONSE=$(curl -s http://localhost:3000/health)
          echo "Health check response: $HEALTH_RESPONSE"

          # Validate health response
          if ! echo "$HEALTH_RESPONSE" | jq -e '.status == "ok" or .status == "healthy"' > /dev/null; then
            echo "Application health check failed"
            exit 1
          fi

      - name: Run load test
        run: |
          LEADS_PER_MINUTE="${{ github.event.inputs.leads_per_minute || '15' }}"
          DURATION_MINUTES="${{ github.event.inputs.duration_minutes || '5' }}"

          echo "Running load test: $LEADS_PER_MINUTE leads/min for $DURATION_MINUTES minutes"

          node scripts/load-test-phase4c.js "$LEADS_PER_MINUTE" "$DURATION_MINUTES"
        id: load-test

      - name: Performance analysis
        run: |
          # Extract latest load test results
          LATEST_RESULTS=$(find docs/EVIDENCE/load -name "*.txt" -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' ' -f2-)

          if [ -z "$LATEST_RESULTS" ]; then
            echo "No load test results found"
            exit 1
          fi

          echo "Analyzing results from: $LATEST_RESULTS"

          # Extract key metrics
          P95_PIPELINE=$(grep "P95 Pipeline Latency" "$LATEST_RESULTS" | grep -o '[0-9]\+ms' | tr -d 'ms' || echo "0")
          SUCCESS_RATE=$(grep "Success Rate" "$LATEST_RESULTS" | grep -o '[0-9.]\+%' | tr -d '%' || echo "0")
          THROUGHPUT=$(grep "Throughput" "$LATEST_RESULTS" | grep -o '[0-9.]\+ leads/min' | grep -o '[0-9.]\+' || echo "0")

          echo "Performance Metrics:"
          echo "  P95 Pipeline Latency: ${P95_PIPELINE}ms"
          echo "  Success Rate: ${SUCCESS_RATE}%"
          echo "  Throughput: ${THROUGHPUT} leads/min"

          # Set outputs for subsequent steps
          echo "p95_latency=${P95_PIPELINE}" >> $GITHUB_OUTPUT
          echo "success_rate=${SUCCESS_RATE}" >> $GITHUB_OUTPUT
          echo "throughput=${THROUGHPUT}" >> $GITHUB_OUTPUT
        id: performance-analysis

      - name: Performance validation
        run: |
          P95_LATENCY="${{ steps.performance-analysis.outputs.p95_latency }}"
          SUCCESS_RATE="${{ steps.performance-analysis.outputs.success_rate }}"
          THROUGHPUT="${{ steps.performance-analysis.outputs.throughput }}"

          echo "Validating performance thresholds..."
          echo "P95 Latency: ${P95_LATENCY}ms (threshold: <500ms)"
          echo "Success Rate: ${SUCCESS_RATE}% (threshold: >99.5%)"
          echo "Throughput: ${THROUGHPUT} leads/min (threshold: >10)"

          # Check thresholds
          if [ "$P95_LATENCY" -gt 500 ]; then
            echo "‚ùå P95 latency exceeds threshold: ${P95_LATENCY}ms > 500ms"
            echo "performance_check=failed" >> $GITHUB_OUTPUT
          elif (( $(echo "$SUCCESS_RATE < 99.5" | bc -l) )); then
            echo "‚ùå Success rate below threshold: ${SUCCESS_RATE}% < 99.5%"
            echo "performance_check=failed" >> $GITHUB_OUTPUT
          elif (( $(echo "$THROUGHPUT < 10" | bc -l) )); then
            echo "‚ùå Throughput below threshold: ${THROUGHPUT} < 10 leads/min"
            echo "performance_check=failed" >> $GITHUB_OUTPUT
          else
            echo "‚úÖ All performance thresholds met"
            echo "performance_check=passed" >> $GITHUB_OUTPUT
          fi
        id: performance-validation

      - name: Generate performance report
        run: |
          cat > performance_report.md << 'EOF'
          # Load Test Performance Report

          ## Test Configuration
          - **Timestamp**: $(date -Iseconds)
          - **Leads per minute**: ${{ github.event.inputs.leads_per_minute || '15' }}
          - **Duration**: ${{ github.event.inputs.duration_minutes || '5' }} minutes
          - **Environment**: GitHub Actions (Ubuntu)

          ## Performance Results

          ### Latency Metrics
          - **P95 Pipeline Latency**: ${{ steps.performance-analysis.outputs.p95_latency }}ms
          - **Threshold**: <500ms
          - **Status**: $([ "${{ steps.performance-validation.outputs.performance_check }}" = "passed" ] && echo "‚úÖ PASS" || echo "‚ùå FAIL")

          ### Reliability Metrics
          - **Success Rate**: ${{ steps.performance-analysis.outputs.success_rate }}%
          - **Threshold**: >99.5%
          - **Status**: $([ "${{ steps.performance-validation.outputs.performance_check }}" = "passed" ] && echo "‚úÖ PASS" || echo "‚ùå FAIL")

          ### Throughput Metrics
          - **Throughput**: ${{ steps.performance-analysis.outputs.throughput }} leads/min
          - **Threshold**: >10 leads/min
          - **Status**: $([ "${{ steps.performance-validation.outputs.performance_check }}" = "passed" ] && echo "‚úÖ PASS" || echo "‚ùå FAIL")

          ## Recommendations

          $(if [ "${{ steps.performance-validation.outputs.performance_check }}" = "failed" ]; then
            echo "### Performance Issues Detected"
            echo ""
            if [ "${{ steps.performance-analysis.outputs.p95_latency }}" -gt 500 ]; then
              echo "- **High Latency**: P95 pipeline latency exceeds 500ms. Consider:"
              echo "  - Implementing caching for industry multipliers"
              echo "  - Optimizing AI scoring algorithms"
              echo "  - Adding async processing for non-critical paths"
              echo "  - Horizontal scaling of application instances"
            fi
            echo ""
            if (( $(echo "${{ steps.performance-analysis.outputs.success_rate }} < 99.5" | bc -l) )); then
              echo "- **Low Success Rate**: Success rate below 99.5%. Investigate:"
              echo "  - Error handling in AI processing pipeline"
              echo "  - Database connection issues"
              echo "  - External API timeouts"
              echo "  - Memory or resource exhaustion"
            fi
            echo ""
            if (( $(echo "${{ steps.performance-analysis.outputs.throughput }} < 10" | bc -l) )); then
              echo "- **Low Throughput**: Throughput below 10 leads/min. Consider:"
              echo "  - Database query optimization"
              echo "  - Connection pooling improvements"
              echo "  - Background job processing"
              echo "  - Load balancer configuration"
            fi
          else
            echo "### All Performance Targets Met ‚úÖ"
            echo ""
            echo "System performance is within acceptable parameters for production deployment."
          fi)

          ## Raw Test Data
          See load test evidence files in \`docs/EVIDENCE/load/\` for detailed metrics and analysis.
          EOF

      - name: Upload load test results
        uses: actions/upload-artifact@v4
        with:
          name: load-test-results
          path: |
            docs/EVIDENCE/load/
            performance_report.md

      - name: Performance alert
        if: steps.performance-validation.outputs.performance_check == 'failed'
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'üö® Performance Regression Detected',
              body: `
            ## Performance Regression Alert

            Load testing has detected performance issues that exceed acceptable thresholds:

            - **P95 Latency**: ${{ steps.performance-analysis.outputs.p95_latency }}ms (threshold: <500ms)
            - **Success Rate**: ${{ steps.performance-analysis.outputs.success_rate }}% (threshold: >99.5%)
            - **Throughput**: ${{ steps.performance-analysis.outputs.throughput }} leads/min (threshold: >10)

            ### Immediate Actions Required:
            1. Review performance report in artifacts
            2. Analyze bottleneck causes
            3. Implement optimization measures
            4. Re-run load tests to validate fixes

            ### Evidence Location:
            - Load test results: \`docs/EVIDENCE/load/\`
            - Performance report: workflow artifacts

            This issue was automatically created by the load testing workflow.
            `,
              labels: ['performance', 'urgent', 'automated']
            });

      - name: Fail on performance regression
        if: steps.performance-validation.outputs.performance_check == 'failed'
        run: |
          echo "‚ùå Performance regression detected. Failing workflow."
          echo "Review the performance report and artifacts for details."
          exit 1
